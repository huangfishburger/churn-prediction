{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script generates weekly user-play features by splitting subscription periods into 7-day windows, computing per-week average play minutes and play counts, handling missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription = pd.read_csv(\"./data/subscription.csv\")\n",
    "history = pd.read_csv(\"./data/history.csv\")\n",
    "subscription.sort_values(by=['sub_start'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segment the period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the latest 'play_date'\n",
    "history.sort_values(by=['play_date'], inplace=True)\n",
    "\n",
    "# Fill missing 'sub_end' values with '2024-01-22'\n",
    "feature = subscription\n",
    "feature['sub_start'] = pd.to_datetime(feature['sub_start'])\n",
    "feature['sub_end'] = feature['sub_end'].fillna('2024-01-22')\n",
    "\n",
    "# Remove data where the duration (sub_end - sub_start) is less than or equal to 7 days\n",
    "feature = feature[feature['sub_end'] > feature['sub_start'] + pd.Timedelta(days=7)]\n",
    "\n",
    "# ivide the period into weekly segments (7 days), starting from 'sub_end' and extending backward until 'sub_start' or a maximum of 3 months is reached\n",
    "feature['sub_start'] = pd.to_datetime(feature['sub_start'])\n",
    "feature['sub_end'] = pd.to_datetime(feature['sub_end'])\n",
    "num_weeks = 13\n",
    "\n",
    "for index, row in feature.iterrows():\n",
    "    for i in range(num_weeks):\n",
    "        if row['sub_end'] - pd.DateOffset(days=7*i) < row['sub_start']:\n",
    "            feature.at[index, f'week{i}'] = np.nan\n",
    "        else:   \n",
    "            feature.at[index, f'week{i}'] = row['sub_end'] - pd.DateOffset(days=7*i)\n",
    "\n",
    "# Retain only the history records that correspond to available feature ids\n",
    "history = history[history['id'].isin(feature['id'])]\n",
    "\n",
    "# Determine the latest date for 'week 12' (or the 12th weekly segment)\n",
    "feature.sort_values(by='week12', ascending=True)\n",
    "\n",
    "# Retain only the history records with a 'play_date' later than '2020-11-15'\n",
    "history['play_date'] = pd.to_datetime(history['play_date'])\n",
    "history = history[history['play_date'] > '2020-11-15']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate weekly usage metrics (e.g., play time, frequency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 13): \n",
    "    print(\"week\", i, \"is processing\")\n",
    "    # Add new columns and initialize them with NaN\n",
    "    feature[f'week{i}_avg_play_minute'] = np.nan \n",
    "    feature[f'week{i}_total_row_count'] = np.nan\n",
    "\n",
    "    # Filter out null values and data containing valid ids\n",
    "    mask = feature[(feature[f'week{i}'].notna()) & (feature[f'week{i-1}'].notna())]\n",
    "    history1 = history[history['id'].isin(mask['id'])]\n",
    "\n",
    "    # Filter data where 'id' is the same AND 'play_date' falls between week i and week i - 1.\n",
    "    for index, row in tqdm(mask.iterrows()):\n",
    "        subset = history1[(history1['id'] == row['id']) & (history1['play_date'] > row[f'week{i}']) & (history1['play_date'] <= row[f'week{i-1}'])]\n",
    "\n",
    "        # Group by 'id' and calculate aggregated statistics.\n",
    "        grouped = subset.groupby('id').agg(\n",
    "            week_avg_play_minute = ('play_minute', 'mean'),\n",
    "            row_count =('id', 'size'),\n",
    "        ).reset_index()\n",
    "\n",
    "        merged = pd.merge(feature, grouped, on='id', how='left')\n",
    "        if not grouped.empty:\n",
    "            feature.at[index, f'week{i}_avg_play_minute'] = grouped['week_avg_play_minute'].values[0]\n",
    "            feature.at[index, f'week{i}_total_row_count'] = grouped['row_count'].values[0]\n",
    "    print(\"week\", i, \"is done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature['sub_start'] = pd.to_datetime(feature['sub_start'])\n",
    "feature['sub_end'] = pd.to_datetime(feature['sub_end'])\n",
    "\n",
    "# Calculate the number of weeks passed\n",
    "feature['weeks_passed'] = np.minimum(12, ((feature['sub_end'] - feature['sub_start']).dt.days / 7).astype(int))\n",
    "\n",
    "\n",
    "columns = feature.columns.tolist()\n",
    "for index, row in feature.iterrows():\n",
    "    weeks_passed = row['weeks_passed']\n",
    "    # Fill NaN values in columns preceding the current week with 0\n",
    "    for i in range(weeks_passed+1):\n",
    "        for column in columns:\n",
    "            if f'week{i}_' in column:\n",
    "                if pd.isnull(row[column]):\n",
    "                    feature.at[index, column] = 0\n",
    "\n",
    "feature.fillna('none', inplace=True)\n",
    "feature.drop(columns=['weeks_passed'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate daily average metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 13):\n",
    "    col_row_count = f\"week{i}_total_row_count\"\n",
    "        \n",
    "    for index, row in feature.iterrows():\n",
    "        if isinstance(row[col_row_count], (int, float)):\n",
    "            feature.at[index, f\"week{i}_avg_row_count_by_day\"] = row[col_row_count] / (7 * i)\n",
    "            \n",
    "feature.fillna('none', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature.to_csv('./data/feature_week.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
